{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 🚀 DATABASE RECOMMENDATION API\n",
        "# =============================================================================\n",
        "\n",
        "# 📦 DEPENDENCIES INSTALLATION\n",
        "print(\"🔄 Installing dependencies...\")\n",
        "\n",
        "# Install Ollama\n",
        "!curl -fsSL https://ollama.ai/install.sh | sh\n",
        "# Install required packages\n",
        "!pip install fastapi uvicorn pyngrok requests\n",
        "!pip install \"pydantic[email]\" jinja2 python-multipart\n",
        "# Import libraries\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "import logging\n",
        "import re\n",
        "import uuid\n",
        "from typing import Dict, List, Optional, Any, Union\n",
        "from pydantic import BaseModel, Field\n",
        "from fastapi import FastAPI, Body, HTTPException\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from enum import Enum\n",
        "\n",
        "# =============================================================================\n",
        "# 🛠️ LOGGING CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(),\n",
        "        logging.FileHandler('database_recommendation.log')\n",
        "    ]\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(\"database_recommendation\")\n",
        "\n",
        "# =============================================================================\n",
        "# 📊 DATA MODELS\n",
        "# =============================================================================\n",
        "\n",
        "class DatabaseType(str, Enum):\n",
        "    POSTGRES = \"postgres\"\n",
        "    CLICKHOUSE = \"clickhouse\"\n",
        "    MYSQL = \"mysql\"\n",
        "    MONGODB = \"mongodb\"\n",
        "    REDIS = \"redis\"\n",
        "    ELASTICSEARCH = \"elasticsearch\"\n",
        "    CASSANDRA = \"cassandra\"\n",
        "\n",
        "class LanguageType(str, Enum):\n",
        "    RU = \"ru\"\n",
        "    EN = \"en\"\n",
        "\n",
        "class DatabaseRecommendationRequest(BaseModel):\n",
        "    use_case: str = Field(..., description=\"Описание варианта использования\")\n",
        "    data_characteristics: Dict[str, Any] = Field(..., description=\"Характеристики данных (может содержать schema_input)\")\n",
        "    performance_requirements: Dict[str, Any] = Field(None, description=\"Требования к производительности\")\n",
        "    input_language: LanguageType = Field(default=LanguageType.RU, description=\"Язык входных данных\")\n",
        "    output_language: LanguageType = Field(default=LanguageType.RU, description=\"Язык ответа\")\n",
        "\n",
        "class DatabaseRecommendation(BaseModel):\n",
        "    database: str = Field(..., description=\"Рекомендуемая база данных\")\n",
        "    reason: str = Field(..., description=\"Обоснование рекомендации\")\n",
        "    pros: List[str] = Field(..., description=\"Преимущества\")\n",
        "    cons: List[str] = Field(..., description=\"Недостатки\")\n",
        "    suitability_score: int = Field(..., description=\"Оценка применимости от 1 до 100\")\n",
        "\n",
        "class DatabaseRecommendationResponse(BaseModel):\n",
        "    recommended_databases: List[DatabaseRecommendation] = Field(..., description=\"Список рекомендованных БД\")\n",
        "    storage_strategy: str = Field(..., description=\"Стратегия хранения данных\")\n",
        "    data_modeling_advice: List[str] = Field(..., description=\"Советы по моделированию данных\")\n",
        "    performance_optimizations: List[str] = Field(..., description=\"Оптимизации производительности\")\n",
        "    success: bool = Field(..., description=\"Статус выполнения\")\n",
        "\n",
        "# =============================================================================\n",
        "# 🎯 OLLAMA SETUP\n",
        "# =============================================================================\n",
        "\n",
        "def setup_ollama():\n",
        "    \"\"\"Start Ollama server in background\"\"\"\n",
        "    logger.info(\"🔧 Starting Ollama server...\")\n",
        "\n",
        "    def run_ollama():\n",
        "        try:\n",
        "            subprocess.run([\"ollama\", \"serve\"], check=True)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            logger.error(f\"Ollama startup error: {e}\")\n",
        "\n",
        "    ollama_thread = threading.Thread(target=run_ollama, daemon=True)\n",
        "    ollama_thread.start()\n",
        "    time.sleep(10)\n",
        "\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            response = requests.get(\"http://localhost:11434/api/tags\", timeout=30)\n",
        "            if response.status_code == 200:\n",
        "                logger.info(\"✅ Ollama server started successfully\")\n",
        "                return True\n",
        "        except:\n",
        "            logger.warning(f\"⚠️ Ollama connection attempt {i+1}/3 failed, retrying...\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    logger.error(\"❌ Could not connect to Ollama server\")\n",
        "    return False\n",
        "\n",
        "def download_model():\n",
        "    \"\"\"Download Mistral 7B model\"\"\"\n",
        "    model_name = \"mistral:7b\"\n",
        "\n",
        "    logger.info(f\"📥 Downloading {model_name}...\")\n",
        "    try:\n",
        "        process = subprocess.run(\n",
        "            [\"ollama\", \"pull\", model_name],\n",
        "            timeout=1800,\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "        if process.returncode == 0:\n",
        "            logger.info(f\"✅ {model_name} downloaded successfully\")\n",
        "            return True\n",
        "        else:\n",
        "            logger.warning(f\"⚠️ {model_name} download issues: {process.stderr}\")\n",
        "            return False\n",
        "    except subprocess.TimeoutExpired:\n",
        "        logger.warning(f\"⚠️ {model_name} download timeout\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ Error downloading {model_name}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Initialize Ollama\n",
        "setup_ollama()\n",
        "logger.info(\"📥 Loading Mistral 7B model...\")\n",
        "download_model()\n",
        "time.sleep(10)\n",
        "\n",
        "# =============================================================================\n",
        "# 🤖 LLM CLIENT\n",
        "# =============================================================================\n",
        "\n",
        "class LLMClient:\n",
        "    def __init__(self):\n",
        "        self.base_url = \"http://localhost:11434\"\n",
        "        self.timeout = 300\n",
        "        self.model = \"mistral:7b\"\n",
        "\n",
        "    def generate_database_recommendation(self, prompt: str) -> str:\n",
        "        \"\"\"Generate database recommendation using Mistral model\"\"\"\n",
        "        return self._generate_content(prompt)\n",
        "\n",
        "    def _generate_content(self, prompt: str) -> str:\n",
        "        \"\"\"Generic content generation method\"\"\"\n",
        "        try:\n",
        "            payload = {\n",
        "                \"model\": self.model,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False,\n",
        "                \"options\": {\n",
        "                    \"temperature\": 0.1,\n",
        "                    \"top_k\": 1,\n",
        "                    \"top_p\": 0.1\n",
        "                }\n",
        "            }\n",
        "\n",
        "            logger.info(f\"🤖 Generating database recommendation with {self.model}...\")\n",
        "            response = requests.post(\n",
        "                f\"{self.base_url}/api/generate\",\n",
        "                json=payload,\n",
        "                timeout=self.timeout\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                content = result.get(\"response\", \"\").strip()\n",
        "\n",
        "                # Clean up the response\n",
        "                content = re.sub(r'```json\\s*', '', content)\n",
        "                content = re.sub(r'```\\s*', '', content)\n",
        "                content = content.strip()\n",
        "\n",
        "                logger.info(f\"✅ Recommendation generated successfully ({len(content)} chars)\")\n",
        "                return content\n",
        "            else:\n",
        "                logger.error(f\"❌ LLM API error: {response.status_code} - {response.text}\")\n",
        "                return f\"ERROR: LLM API returned {response.status_code}\"\n",
        "\n",
        "        except requests.exceptions.Timeout:\n",
        "            logger.error(\"❌ LLM request timeout\")\n",
        "            return \"ERROR: Request timeout\"\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ LLM request failed: {str(e)}\")\n",
        "            return f\"ERROR: {str(e)}\"\n",
        "\n",
        "# =============================================================================\n",
        "# 🎯 DATABASE RECOMMENDATION SERVICE\n",
        "# =============================================================================\n",
        "\n",
        "class DatabaseRecommendationService:\n",
        "    def __init__(self):\n",
        "        self.llm_client = LLMClient()\n",
        "\n",
        "    def recommend_databases(self, request: DatabaseRecommendationRequest) -> DatabaseRecommendationResponse:\n",
        "        \"\"\"Generate database recommendations based on use case and data characteristics\"\"\"\n",
        "        logger.info(\"🎯 Starting database recommendation analysis...\")\n",
        "\n",
        "        try:\n",
        "            # Create comprehensive prompt for database recommendation\n",
        "            prompt = self._create_recommendation_prompt(request)\n",
        "\n",
        "            # Generate recommendation using LLM\n",
        "            recommendation_text = self.llm_client.generate_database_recommendation(prompt)\n",
        "\n",
        "            # Parse the response into structured format\n",
        "            parsed_recommendation = self._parse_recommendation_response(recommendation_text, request.output_language)\n",
        "\n",
        "            logger.info(\"✅ Database recommendation completed successfully\")\n",
        "            return parsed_recommendation\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ Database recommendation failed: {str(e)}\")\n",
        "            # Return fallback recommendation\n",
        "            return self._get_fallback_recommendation(request.output_language)\n",
        "\n",
        "    def _create_recommendation_prompt(self, request: DatabaseRecommendationRequest) -> str:\n",
        "        \"\"\"Create detailed prompt for database recommendation\"\"\"\n",
        "\n",
        "        # Extract schema information if present\n",
        "        schema_info = \"\"\n",
        "        if \"inputs\" in request.data_characteristics:\n",
        "            inputs = request.data_characteristics.get(\"inputs\", [])\n",
        "            if inputs:\n",
        "                schema_data = inputs[0].get(\"schema\", {})\n",
        "                if isinstance(schema_data, dict) and \"fields\" in schema_data:\n",
        "                    schema_info = f\"Schema fields: {len(schema_data['fields'])}\"\n",
        "                elif isinstance(schema_data, str) and \"CREATE TABLE\" in schema_data.upper():\n",
        "                    schema_info = \"DDL schema provided with CREATE TABLE statements\"\n",
        "\n",
        "        language_instruction = self._get_language_instruction(request.input_language, request.output_language)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "{language_instruction}\n",
        "\n",
        "DATABASE RECOMMENDATION ANALYSIS REQUEST:\n",
        "\n",
        "USE CASE:\n",
        "{request.use_case}\n",
        "\n",
        "DATA CHARACTERISTICS:\n",
        "{json.dumps(request.data_characteristics, indent=2, ensure_ascii=False)}\n",
        "{schema_info}\n",
        "\n",
        "PERFORMANCE REQUIREMENTS:\n",
        "{json.dumps(request.performance_requirements, indent=2, ensure_ascii=False)}\n",
        "\n",
        "ANALYSIS CRITERIA:\n",
        "1. Data Volume & Velocity - размер данных и скорость поступления\n",
        "2. Query Patterns - типы запросов (OLTP, OLAP, аналитические)\n",
        "3. Data Structure - структурированные, полуструктурированные, неструктурированные\n",
        "4. Consistency Requirements - требования к консистентности\n",
        "5. Scalability Needs - потребности в масштабировании\n",
        "6. Operational Complexity - операционная сложность\n",
        "\n",
        "AVAILABLE DATABASES TO CONSIDER:\n",
        "- PostgreSQL - универсальная реляционная БД, ACID, JSON поддержка\n",
        "- ClickHouse - колоночная БД для аналитики, высокая производительность\n",
        "- MySQL - популярная реляционная БД, веб-приложения\n",
        "- MongoDB - документная БД, гибкая схема\n",
        "- Redis - in-memory БД, кэширование, очереди\n",
        "- Elasticsearch - поиск и аналитика, полнотекстовый поиск\n",
        "- Cassandra - распределенная БД, высокая доступность\n",
        "\n",
        "REQUIRED RESPONSE FORMAT (JSON):\n",
        "{{\n",
        "  \"recommended_databases\": [\n",
        "    {{\n",
        "      \"database\": \"database_name\",\n",
        "      \"reason\": \"detailed explanation\",\n",
        "      \"pros\": [\"advantage1\", \"advantage2\"],\n",
        "      \"cons\": [\"disadvantage1\", \"disadvantage2\"],\n",
        "      \"suitability_score\": 85\n",
        "    }}\n",
        "  ],\n",
        "  \"storage_strategy\": \"overall storage approach\",\n",
        "  \"data_modeling_advice\": [\"advice1\", \"advice2\"],\n",
        "  \"performance_optimizations\": [\"optimization1\", \"optimization2\"],\n",
        "  \"success\": true\n",
        "}}\n",
        "\n",
        "IMPORTANT:\n",
        "- Provide 2-3 most suitable databases with scores 70-100\n",
        "- Be specific and practical in recommendations\n",
        "- Avoid duplicate information across different sections\n",
        "- Focus on real-world applicability\n",
        "- Consider both technical and operational aspects\n",
        "- Provide actionable advice\n",
        "\n",
        "RETURN ONLY VALID JSON WITHOUT ANY ADDITIONAL TEXT.\n",
        "\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def _get_language_instruction(self, input_lang: LanguageType, output_lang: LanguageType) -> str:\n",
        "        \"\"\"Get language instruction for the prompt\"\"\"\n",
        "        if input_lang == LanguageType.EN and output_lang == LanguageType.EN:\n",
        "            return \"Please provide the response in English. Keep technical terms in English.\"\n",
        "        elif input_lang == LanguageType.RU and output_lang == LanguageType.EN:\n",
        "            return \"The input is in Russian but please provide the response in English. Keep technical terms in English.\"\n",
        "        elif input_lang == LanguageType.EN and output_lang == LanguageType.RU:\n",
        "            return \"The input is in English but please provide the response in Russian. Keep technical terms in English.\"\n",
        "        else:\n",
        "            return \"Please provide the response in Russian. Keep technical terms in English.\"\n",
        "\n",
        "    def _parse_recommendation_response(self, response_text: str, output_language: LanguageType) -> DatabaseRecommendationResponse:\n",
        "        \"\"\"Parse LLM response into structured format\"\"\"\n",
        "        try:\n",
        "            # Try to extract JSON from response\n",
        "            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "            if json_match:\n",
        "                json_str = json_match.group()\n",
        "                data = json.loads(json_str)\n",
        "\n",
        "                # Validate and convert to response model\n",
        "                return DatabaseRecommendationResponse(\n",
        "                    recommended_databases=[\n",
        "                        DatabaseRecommendation(\n",
        "                            database=db[\"database\"],\n",
        "                            reason=db[\"reason\"],\n",
        "                            pros=db[\"pros\"],\n",
        "                            cons=db[\"cons\"],\n",
        "                            suitability_score=db[\"suitability_score\"]\n",
        "                        ) for db in data[\"recommended_databases\"]\n",
        "                    ],\n",
        "                    storage_strategy=data[\"storage_strategy\"],\n",
        "                    data_modeling_advice=data[\"data_modeling_advice\"],\n",
        "                    performance_optimizations=data[\"performance_optimizations\"],\n",
        "                    success=data[\"success\"]\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\"No JSON found in response\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to parse LLM response, using fallback: {e}\")\n",
        "            return self._get_fallback_recommendation(output_language)\n",
        "\n",
        "    def _get_fallback_recommendation(self, output_language: LanguageType) -> DatabaseRecommendationResponse:\n",
        "        \"\"\"Provide fallback recommendation when LLM fails\"\"\"\n",
        "        if output_language == LanguageType.EN:\n",
        "            return DatabaseRecommendationResponse(\n",
        "                recommended_databases=[\n",
        "                    DatabaseRecommendation(\n",
        "                        database=\"PostgreSQL\",\n",
        "                        reason=\"Universal relational database with excellent ACID compliance and JSON support\",\n",
        "                        pros=[\"Strong consistency\", \"Rich feature set\", \"Great community support\", \"JSON and spatial data support\"],\n",
        "                        cons=[\"Can require more tuning for high-scale analytics\", \"Less optimized for columnar operations than ClickHouse\"],\n",
        "                        suitability_score=80\n",
        "                    ),\n",
        "                    DatabaseRecommendation(\n",
        "                        database=\"ClickHouse\",\n",
        "                        reason=\"Column-oriented database optimized for analytical queries and large-scale data processing\",\n",
        "                        pros=[\"Excellent for analytical workloads\", \"High compression rates\", \"Fast aggregations\"],\n",
        "                        cons=[\"Weaker for transactional workloads\", \"Less mature ecosystem than PostgreSQL\"],\n",
        "                        suitability_score=75\n",
        "                    )\n",
        "                ],\n",
        "                storage_strategy=\"Consider using PostgreSQL for transactional data and ClickHouse for analytical workloads in a dual-database architecture\",\n",
        "                data_modeling_advice=[\n",
        "                    \"Normalize data for transactional workloads\",\n",
        "                    \"Use denormalized structures for analytical queries\",\n",
        "                    \"Consider partitioning for large datasets\"\n",
        "                ],\n",
        "                performance_optimizations=[\n",
        "                    \"Use appropriate indexes for query patterns\",\n",
        "                    \"Consider connection pooling for high concurrency\",\n",
        "                    \"Monitor and tune database configuration parameters\"\n",
        "                ],\n",
        "                success=True\n",
        "            )\n",
        "        else:\n",
        "            return DatabaseRecommendationResponse(\n",
        "                recommended_databases=[\n",
        "                    DatabaseRecommendation(\n",
        "                        database=\"PostgreSQL\",\n",
        "                        reason=\"Универсальная реляционная СУБД с отличной поддержкой ACID и JSON\",\n",
        "                        pros=[\"Сильная консистентность\", \"Богатый функционал\", \"Отличная поддержка сообщества\", \"Поддержка JSON и пространственных данных\"],\n",
        "                        cons=[\"Требует настройки для аналитики больших объемов\", \"Менее оптимизирована для колоночных операций чем ClickHouse\"],\n",
        "                        suitability_score=80\n",
        "                    ),\n",
        "                    DatabaseRecommendation(\n",
        "                        database=\"ClickHouse\",\n",
        "                        reason=\"Колоночная СУБД оптимизирована для аналитических запросов и обработки больших данных\",\n",
        "                        pros=[\"Отлично подходит для аналитических нагрузок\", \"Высокий уровень сжатия\", \"Быстрые агрегации\"],\n",
        "                        cons=[\"Слабее для транзакционных нагрузок\", \"Менее зрелая экосистема чем PostgreSQL\"],\n",
        "                        suitability_score=75\n",
        "                    )\n",
        "                ],\n",
        "                storage_strategy=\"Рекомендуется использовать PostgreSQL для транзакционных данных и ClickHouse для аналитических нагрузок в архитектуре с двумя БД\",\n",
        "                data_modeling_advice=[\n",
        "                    \"Нормализуйте данные для транзакционных нагрузок\",\n",
        "                    \"Используйте денормализованные структуры для аналитических запросов\",\n",
        "                    \"Рассмотрите партиционирование для больших наборов данных\"\n",
        "                ],\n",
        "                performance_optimizations=[\n",
        "                    \"Используйте соответствующие индексы для шаблонов запросов\",\n",
        "                    \"Рассмотрите пул соединений для высокой конкурентности\",\n",
        "                    \"Мониторьте и настраивайте параметры конфигурации БД\"\n",
        "                ],\n",
        "                success=True\n",
        "            )\n",
        "\n",
        "# =============================================================================\n",
        "# 🚀 FASTAPI APPLICATION\n",
        "# =============================================================================\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"Database Recommendation API\",\n",
        "    description=\"API для рекомендации подходящих баз данных на основе варианта использования\",\n",
        "    version=\"1.0\"\n",
        ")\n",
        "\n",
        "database_recommendation_service = DatabaseRecommendationService()\n",
        "\n",
        "@app.post(\"/recommend-database\", response_model=DatabaseRecommendationResponse)\n",
        "async def recommend_database(request: DatabaseRecommendationRequest = Body(...)):\n",
        "    \"\"\"Рекомендация подходящих баз данных на основе варианта использования и характеристик данных\"\"\"\n",
        "    logger.info(\"🎯 Starting database recommendation analysis\")\n",
        "\n",
        "    try:\n",
        "        recommendation = database_recommendation_service.recommend_databases(request)\n",
        "\n",
        "        logger.info(\"✅ Database recommendation completed successfully\")\n",
        "        return recommendation\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ Database recommendation failed: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=f\"Database recommendation failed: {str(e)}\")\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"service\": \"Database Recommendation API\",\n",
        "        \"version\": \"1.0\",\n",
        "        \"supported_databases\": [db.value for db in DatabaseType],\n",
        "        \"model\": \"mistral:7b\"\n",
        "    }\n",
        "\n",
        "# =============================================================================\n",
        "# 🚀 SERVER STARTUP\n",
        "# =============================================================================\n",
        "\n",
        "def run_server():\n",
        "    \"\"\"Run FastAPI server\"\"\"\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=9008)\n",
        "\n",
        "# Start server in background thread\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "logger.info(\"⏳ Starting Database Recommendation server...\")\n",
        "time.sleep(5)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 🔗 NGROK TUNNEL\n",
        "# =============================================================================\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"33VYITl8jw9h78PdWIl1hgXJDk0_umeC43CgfdBrAnnEjBQu\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "try:\n",
        "    public_tunnel = ngrok.connect(9008, bind_tls=True)\n",
        "    public_url = public_tunnel.public_url\n",
        "except Exception as e:\n",
        "    logger.error(f\"❌ Ngrok error: {e}\")\n",
        "    print(f\"❌ Ngrok failed: {e}\")\n",
        "    print(\"📡 Server running locally on http://localhost:9008\")"
      ],
      "metadata": {
        "id": "MovpwFppi_6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔄 KEEP-ALIVE LOOP FOR SERVER AND SESSION\n",
        "import time\n",
        "import threading\n",
        "\n",
        "def keep_alive():\n",
        "    \"\"\"Простой цикл для поддержания активности сервера и сессии\"\"\"\n",
        "    while True:\n",
        "        print(f\"🕒 Session alive at {time.strftime('%H:%M:%S')}\")\n",
        "        time.sleep(60)  # Сообщение каждую минуту\n",
        "\n",
        "# Запускаем в фоновом потоке\n",
        "keep_alive_thread = threading.Thread(target=keep_alive, daemon=True)\n",
        "keep_alive_thread.start()\n",
        "\n",
        "print(\"✅ Keep-alive loop started - server will stay active\")"
      ],
      "metadata": {
        "id": "FgForPt4oxpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
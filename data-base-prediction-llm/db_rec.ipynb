{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# üöÄ DATABASE RECOMMENDATION API\n",
        "# =============================================================================\n",
        "\n",
        "# üì¶ DEPENDENCIES INSTALLATION\n",
        "print(\"üîÑ Installing dependencies...\")\n",
        "\n",
        "# Install Ollama\n",
        "!curl -fsSL https://ollama.ai/install.sh | sh\n",
        "# Install required packages\n",
        "!pip install fastapi uvicorn pyngrok requests\n",
        "!pip install \"pydantic[email]\" jinja2 python-multipart\n",
        "# Import libraries\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "import logging\n",
        "import re\n",
        "import uuid\n",
        "from typing import Dict, List, Optional, Any, Union\n",
        "from pydantic import BaseModel, Field\n",
        "from fastapi import FastAPI, Body, HTTPException\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "from enum import Enum\n",
        "\n",
        "# =============================================================================\n",
        "# üõ†Ô∏è LOGGING CONFIGURATION\n",
        "# =============================================================================\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(),\n",
        "        logging.FileHandler('database_recommendation.log')\n",
        "    ]\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(\"database_recommendation\")\n",
        "\n",
        "# =============================================================================\n",
        "# üìä DATA MODELS\n",
        "# =============================================================================\n",
        "\n",
        "class DatabaseType(str, Enum):\n",
        "    POSTGRES = \"postgres\"\n",
        "    CLICKHOUSE = \"clickhouse\"\n",
        "    MYSQL = \"mysql\"\n",
        "    MONGODB = \"mongodb\"\n",
        "    REDIS = \"redis\"\n",
        "    ELASTICSEARCH = \"elasticsearch\"\n",
        "    CASSANDRA = \"cassandra\"\n",
        "\n",
        "class LanguageType(str, Enum):\n",
        "    RU = \"ru\"\n",
        "    EN = \"en\"\n",
        "\n",
        "class DatabaseRecommendationRequest(BaseModel):\n",
        "    use_case: str = Field(..., description=\"–û–ø–∏—Å–∞–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\")\n",
        "    data_characteristics: Dict[str, Any] = Field(..., description=\"–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å schema_input)\")\n",
        "    performance_requirements: Dict[str, Any] = Field(None, description=\"–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\")\n",
        "    input_language: LanguageType = Field(default=LanguageType.RU, description=\"–Ø–∑—ã–∫ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\")\n",
        "    output_language: LanguageType = Field(default=LanguageType.RU, description=\"–Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞\")\n",
        "\n",
        "class DatabaseRecommendation(BaseModel):\n",
        "    database: str = Field(..., description=\"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö\")\n",
        "    reason: str = Field(..., description=\"–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\")\n",
        "    pros: List[str] = Field(..., description=\"–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞\")\n",
        "    cons: List[str] = Field(..., description=\"–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏\")\n",
        "    suitability_score: int = Field(..., description=\"–û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç–∏ –æ—Ç 1 –¥–æ 100\")\n",
        "\n",
        "class DatabaseRecommendationResponse(BaseModel):\n",
        "    recommended_databases: List[DatabaseRecommendation] = Field(..., description=\"–°–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –ë–î\")\n",
        "    storage_strategy: str = Field(..., description=\"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö\")\n",
        "    data_modeling_advice: List[str] = Field(..., description=\"–°–æ–≤–µ—Ç—ã –ø–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é –¥–∞–Ω–Ω—ã—Ö\")\n",
        "    performance_optimizations: List[str] = Field(..., description=\"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\")\n",
        "    success: bool = Field(..., description=\"–°—Ç–∞—Ç—É—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\")\n",
        "\n",
        "# =============================================================================\n",
        "# üéØ OLLAMA SETUP\n",
        "# =============================================================================\n",
        "\n",
        "def setup_ollama():\n",
        "    \"\"\"Start Ollama server in background\"\"\"\n",
        "    logger.info(\"üîß Starting Ollama server...\")\n",
        "\n",
        "    def run_ollama():\n",
        "        try:\n",
        "            subprocess.run([\"ollama\", \"serve\"], check=True)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            logger.error(f\"Ollama startup error: {e}\")\n",
        "\n",
        "    ollama_thread = threading.Thread(target=run_ollama, daemon=True)\n",
        "    ollama_thread.start()\n",
        "    time.sleep(10)\n",
        "\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            response = requests.get(\"http://localhost:11434/api/tags\", timeout=30)\n",
        "            if response.status_code == 200:\n",
        "                logger.info(\"‚úÖ Ollama server started successfully\")\n",
        "                return True\n",
        "        except:\n",
        "            logger.warning(f\"‚ö†Ô∏è Ollama connection attempt {i+1}/3 failed, retrying...\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    logger.error(\"‚ùå Could not connect to Ollama server\")\n",
        "    return False\n",
        "\n",
        "def download_model():\n",
        "    \"\"\"Download Mistral 7B model\"\"\"\n",
        "    model_name = \"mistral:7b\"\n",
        "\n",
        "    logger.info(f\"üì• Downloading {model_name}...\")\n",
        "    try:\n",
        "        process = subprocess.run(\n",
        "            [\"ollama\", \"pull\", model_name],\n",
        "            timeout=1800,\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "        if process.returncode == 0:\n",
        "            logger.info(f\"‚úÖ {model_name} downloaded successfully\")\n",
        "            return True\n",
        "        else:\n",
        "            logger.warning(f\"‚ö†Ô∏è {model_name} download issues: {process.stderr}\")\n",
        "            return False\n",
        "    except subprocess.TimeoutExpired:\n",
        "        logger.warning(f\"‚ö†Ô∏è {model_name} download timeout\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        logger.error(f\"‚ùå Error downloading {model_name}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Initialize Ollama\n",
        "setup_ollama()\n",
        "logger.info(\"üì• Loading Mistral 7B model...\")\n",
        "download_model()\n",
        "time.sleep(10)\n",
        "\n",
        "# =============================================================================\n",
        "# ü§ñ LLM CLIENT\n",
        "# =============================================================================\n",
        "\n",
        "class LLMClient:\n",
        "    def __init__(self):\n",
        "        self.base_url = \"http://localhost:11434\"\n",
        "        self.timeout = 300\n",
        "        self.model = \"mistral:7b\"\n",
        "\n",
        "    def generate_database_recommendation(self, prompt: str) -> str:\n",
        "        \"\"\"Generate database recommendation using Mistral model\"\"\"\n",
        "        return self._generate_content(prompt)\n",
        "\n",
        "    def _generate_content(self, prompt: str) -> str:\n",
        "        \"\"\"Generic content generation method\"\"\"\n",
        "        try:\n",
        "            payload = {\n",
        "                \"model\": self.model,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False,\n",
        "                \"options\": {\n",
        "                    \"temperature\": 0.1,\n",
        "                    \"top_k\": 1,\n",
        "                    \"top_p\": 0.1\n",
        "                }\n",
        "            }\n",
        "\n",
        "            logger.info(f\"ü§ñ Generating database recommendation with {self.model}...\")\n",
        "            response = requests.post(\n",
        "                f\"{self.base_url}/api/generate\",\n",
        "                json=payload,\n",
        "                timeout=self.timeout\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                content = result.get(\"response\", \"\").strip()\n",
        "\n",
        "                # Clean up the response\n",
        "                content = re.sub(r'```json\\s*', '', content)\n",
        "                content = re.sub(r'```\\s*', '', content)\n",
        "                content = content.strip()\n",
        "\n",
        "                logger.info(f\"‚úÖ Recommendation generated successfully ({len(content)} chars)\")\n",
        "                return content\n",
        "            else:\n",
        "                logger.error(f\"‚ùå LLM API error: {response.status_code} - {response.text}\")\n",
        "                return f\"ERROR: LLM API returned {response.status_code}\"\n",
        "\n",
        "        except requests.exceptions.Timeout:\n",
        "            logger.error(\"‚ùå LLM request timeout\")\n",
        "            return \"ERROR: Request timeout\"\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå LLM request failed: {str(e)}\")\n",
        "            return f\"ERROR: {str(e)}\"\n",
        "\n",
        "# =============================================================================\n",
        "# üéØ DATABASE RECOMMENDATION SERVICE\n",
        "# =============================================================================\n",
        "\n",
        "class DatabaseRecommendationService:\n",
        "    def __init__(self):\n",
        "        self.llm_client = LLMClient()\n",
        "\n",
        "    def recommend_databases(self, request: DatabaseRecommendationRequest) -> DatabaseRecommendationResponse:\n",
        "        \"\"\"Generate database recommendations based on use case and data characteristics\"\"\"\n",
        "        logger.info(\"üéØ Starting database recommendation analysis...\")\n",
        "\n",
        "        try:\n",
        "            # Create comprehensive prompt for database recommendation\n",
        "            prompt = self._create_recommendation_prompt(request)\n",
        "\n",
        "            # Generate recommendation using LLM\n",
        "            recommendation_text = self.llm_client.generate_database_recommendation(prompt)\n",
        "\n",
        "            # Parse the response into structured format\n",
        "            parsed_recommendation = self._parse_recommendation_response(recommendation_text, request.output_language)\n",
        "\n",
        "            logger.info(\"‚úÖ Database recommendation completed successfully\")\n",
        "            return parsed_recommendation\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"‚ùå Database recommendation failed: {str(e)}\")\n",
        "            # Return fallback recommendation\n",
        "            return self._get_fallback_recommendation(request.output_language)\n",
        "\n",
        "    def _create_recommendation_prompt(self, request: DatabaseRecommendationRequest) -> str:\n",
        "        \"\"\"Create detailed prompt for database recommendation\"\"\"\n",
        "\n",
        "        # Extract schema information if present\n",
        "        schema_info = \"\"\n",
        "        if \"inputs\" in request.data_characteristics:\n",
        "            inputs = request.data_characteristics.get(\"inputs\", [])\n",
        "            if inputs:\n",
        "                schema_data = inputs[0].get(\"schema\", {})\n",
        "                if isinstance(schema_data, dict) and \"fields\" in schema_data:\n",
        "                    schema_info = f\"Schema fields: {len(schema_data['fields'])}\"\n",
        "                elif isinstance(schema_data, str) and \"CREATE TABLE\" in schema_data.upper():\n",
        "                    schema_info = \"DDL schema provided with CREATE TABLE statements\"\n",
        "\n",
        "        language_instruction = self._get_language_instruction(request.input_language, request.output_language)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "{language_instruction}\n",
        "\n",
        "DATABASE RECOMMENDATION ANALYSIS REQUEST:\n",
        "\n",
        "USE CASE:\n",
        "{request.use_case}\n",
        "\n",
        "DATA CHARACTERISTICS:\n",
        "{json.dumps(request.data_characteristics, indent=2, ensure_ascii=False)}\n",
        "{schema_info}\n",
        "\n",
        "PERFORMANCE REQUIREMENTS:\n",
        "{json.dumps(request.performance_requirements, indent=2, ensure_ascii=False)}\n",
        "\n",
        "ANALYSIS CRITERIA:\n",
        "1. Data Volume & Velocity - —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –∏ —Å–∫–æ—Ä–æ—Å—Ç—å –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è\n",
        "2. Query Patterns - —Ç–∏–ø—ã –∑–∞–ø—Ä–æ—Å–æ–≤ (OLTP, OLAP, –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ)\n",
        "3. Data Structure - —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –ø–æ–ª—É—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ, –Ω–µ—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ\n",
        "4. Consistency Requirements - —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏\n",
        "5. Scalability Needs - –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –≤ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏\n",
        "6. Operational Complexity - –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å\n",
        "\n",
        "AVAILABLE DATABASES TO CONSIDER:\n",
        "- PostgreSQL - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –ë–î, ACID, JSON –ø–æ–¥–¥–µ—Ä–∂–∫–∞\n",
        "- ClickHouse - –∫–æ–ª–æ–Ω–æ—á–Ω–∞—è –ë–î –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏, –≤—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å\n",
        "- MySQL - –ø–æ–ø—É–ª—è—Ä–Ω–∞—è —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –ë–î, –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è\n",
        "- MongoDB - –¥–æ–∫—É–º–µ–Ω—Ç–Ω–∞—è –ë–î, –≥–∏–±–∫–∞—è —Å—Ö–µ–º–∞\n",
        "- Redis - in-memory –ë–î, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ, –æ—á–µ—Ä–µ–¥–∏\n",
        "- Elasticsearch - –ø–æ–∏—Å–∫ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞, –ø–æ–ª–Ω–æ—Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫\n",
        "- Cassandra - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –ë–î, –≤—ã—Å–æ–∫–∞—è –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å\n",
        "\n",
        "REQUIRED RESPONSE FORMAT (JSON):\n",
        "{{\n",
        "  \"recommended_databases\": [\n",
        "    {{\n",
        "      \"database\": \"database_name\",\n",
        "      \"reason\": \"detailed explanation\",\n",
        "      \"pros\": [\"advantage1\", \"advantage2\"],\n",
        "      \"cons\": [\"disadvantage1\", \"disadvantage2\"],\n",
        "      \"suitability_score\": 85\n",
        "    }}\n",
        "  ],\n",
        "  \"storage_strategy\": \"overall storage approach\",\n",
        "  \"data_modeling_advice\": [\"advice1\", \"advice2\"],\n",
        "  \"performance_optimizations\": [\"optimization1\", \"optimization2\"],\n",
        "  \"success\": true\n",
        "}}\n",
        "\n",
        "IMPORTANT:\n",
        "- Provide 2-3 most suitable databases with scores 70-100\n",
        "- Be specific and practical in recommendations\n",
        "- Avoid duplicate information across different sections\n",
        "- Focus on real-world applicability\n",
        "- Consider both technical and operational aspects\n",
        "- Provide actionable advice\n",
        "\n",
        "RETURN ONLY VALID JSON WITHOUT ANY ADDITIONAL TEXT.\n",
        "\"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def _get_language_instruction(self, input_lang: LanguageType, output_lang: LanguageType) -> str:\n",
        "        \"\"\"Get language instruction for the prompt\"\"\"\n",
        "        if input_lang == LanguageType.EN and output_lang == LanguageType.EN:\n",
        "            return \"Please provide the response in English. Keep technical terms in English.\"\n",
        "        elif input_lang == LanguageType.RU and output_lang == LanguageType.EN:\n",
        "            return \"The input is in Russian but please provide the response in English. Keep technical terms in English.\"\n",
        "        elif input_lang == LanguageType.EN and output_lang == LanguageType.RU:\n",
        "            return \"The input is in English but please provide the response in Russian. Keep technical terms in English.\"\n",
        "        else:\n",
        "            return \"Please provide the response in Russian. Keep technical terms in English.\"\n",
        "\n",
        "    def _parse_recommendation_response(self, response_text: str, output_language: LanguageType) -> DatabaseRecommendationResponse:\n",
        "        \"\"\"Parse LLM response into structured format\"\"\"\n",
        "        try:\n",
        "            # Try to extract JSON from response\n",
        "            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "            if json_match:\n",
        "                json_str = json_match.group()\n",
        "                data = json.loads(json_str)\n",
        "\n",
        "                # Validate and convert to response model\n",
        "                return DatabaseRecommendationResponse(\n",
        "                    recommended_databases=[\n",
        "                        DatabaseRecommendation(\n",
        "                            database=db[\"database\"],\n",
        "                            reason=db[\"reason\"],\n",
        "                            pros=db[\"pros\"],\n",
        "                            cons=db[\"cons\"],\n",
        "                            suitability_score=db[\"suitability_score\"]\n",
        "                        ) for db in data[\"recommended_databases\"]\n",
        "                    ],\n",
        "                    storage_strategy=data[\"storage_strategy\"],\n",
        "                    data_modeling_advice=data[\"data_modeling_advice\"],\n",
        "                    performance_optimizations=data[\"performance_optimizations\"],\n",
        "                    success=data[\"success\"]\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\"No JSON found in response\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed to parse LLM response, using fallback: {e}\")\n",
        "            return self._get_fallback_recommendation(output_language)\n",
        "\n",
        "    def _get_fallback_recommendation(self, output_language: LanguageType) -> DatabaseRecommendationResponse:\n",
        "        \"\"\"Provide fallback recommendation when LLM fails\"\"\"\n",
        "        if output_language == LanguageType.EN:\n",
        "            return DatabaseRecommendationResponse(\n",
        "                recommended_databases=[\n",
        "                    DatabaseRecommendation(\n",
        "                        database=\"PostgreSQL\",\n",
        "                        reason=\"Universal relational database with excellent ACID compliance and JSON support\",\n",
        "                        pros=[\"Strong consistency\", \"Rich feature set\", \"Great community support\", \"JSON and spatial data support\"],\n",
        "                        cons=[\"Can require more tuning for high-scale analytics\", \"Less optimized for columnar operations than ClickHouse\"],\n",
        "                        suitability_score=80\n",
        "                    ),\n",
        "                    DatabaseRecommendation(\n",
        "                        database=\"ClickHouse\",\n",
        "                        reason=\"Column-oriented database optimized for analytical queries and large-scale data processing\",\n",
        "                        pros=[\"Excellent for analytical workloads\", \"High compression rates\", \"Fast aggregations\"],\n",
        "                        cons=[\"Weaker for transactional workloads\", \"Less mature ecosystem than PostgreSQL\"],\n",
        "                        suitability_score=75\n",
        "                    )\n",
        "                ],\n",
        "                storage_strategy=\"Consider using PostgreSQL for transactional data and ClickHouse for analytical workloads in a dual-database architecture\",\n",
        "                data_modeling_advice=[\n",
        "                    \"Normalize data for transactional workloads\",\n",
        "                    \"Use denormalized structures for analytical queries\",\n",
        "                    \"Consider partitioning for large datasets\"\n",
        "                ],\n",
        "                performance_optimizations=[\n",
        "                    \"Use appropriate indexes for query patterns\",\n",
        "                    \"Consider connection pooling for high concurrency\",\n",
        "                    \"Monitor and tune database configuration parameters\"\n",
        "                ],\n",
        "                success=True\n",
        "            )\n",
        "        else:\n",
        "            return DatabaseRecommendationResponse(\n",
        "                recommended_databases=[\n",
        "                    DatabaseRecommendation(\n",
        "                        database=\"PostgreSQL\",\n",
        "                        reason=\"–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –°–£–ë–î —Å –æ—Ç–ª–∏—á–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π ACID –∏ JSON\",\n",
        "                        pros=[\"–°–∏–ª—å–Ω–∞—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å\", \"–ë–æ–≥–∞—Ç—ã–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª\", \"–û—Ç–ª–∏—á–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞\", \"–ü–æ–¥–¥–µ—Ä–∂–∫–∞ JSON –∏ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\"],\n",
        "                        cons=[\"–¢—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤\", \"–ú–µ–Ω–µ–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –∫–æ–ª–æ–Ω–æ—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —á–µ–º ClickHouse\"],\n",
        "                        suitability_score=80\n",
        "                    ),\n",
        "                    DatabaseRecommendation(\n",
        "                        database=\"ClickHouse\",\n",
        "                        reason=\"–ö–æ–ª–æ–Ω–æ—á–Ω–∞—è –°–£–ë–î –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö\",\n",
        "                        pros=[\"–û—Ç–ª–∏—á–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫\", \"–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Å–∂–∞—Ç–∏—è\", \"–ë—ã—Å—Ç—Ä—ã–µ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏\"],\n",
        "                        cons=[\"–°–ª–∞–±–µ–µ –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –Ω–∞–≥—Ä—É–∑–æ–∫\", \"–ú–µ–Ω–µ–µ –∑—Ä–µ–ª–∞—è —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞ —á–µ–º PostgreSQL\"],\n",
        "                        suitability_score=75\n",
        "                    )\n",
        "                ],\n",
        "                storage_strategy=\"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PostgreSQL –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ ClickHouse –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ —Å –¥–≤—É–º—è –ë–î\",\n",
        "                data_modeling_advice=[\n",
        "                    \"–ù–æ—Ä–º–∞–ª–∏–∑—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –Ω–∞–≥—Ä—É–∑–æ–∫\",\n",
        "                    \"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤\",\n",
        "                    \"–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö\"\n",
        "                ],\n",
        "                performance_optimizations=[\n",
        "                    \"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —à–∞–±–ª–æ–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤\",\n",
        "                    \"–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø—É–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –¥–ª—è –≤—ã—Å–æ–∫–æ–π –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏\",\n",
        "                    \"–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ë–î\"\n",
        "                ],\n",
        "                success=True\n",
        "            )\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ FASTAPI APPLICATION\n",
        "# =============================================================================\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"Database Recommendation API\",\n",
        "    description=\"API –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\",\n",
        "    version=\"1.0\"\n",
        ")\n",
        "\n",
        "database_recommendation_service = DatabaseRecommendationService()\n",
        "\n",
        "@app.post(\"/recommend-database\", response_model=DatabaseRecommendationResponse)\n",
        "async def recommend_database(request: DatabaseRecommendationRequest = Body(...)):\n",
        "    \"\"\"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö\"\"\"\n",
        "    logger.info(\"üéØ Starting database recommendation analysis\")\n",
        "\n",
        "    try:\n",
        "        recommendation = database_recommendation_service.recommend_databases(request)\n",
        "\n",
        "        logger.info(\"‚úÖ Database recommendation completed successfully\")\n",
        "        return recommendation\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"‚ùå Database recommendation failed: {str(e)}\")\n",
        "        raise HTTPException(status_code=500, detail=f\"Database recommendation failed: {str(e)}\")\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"Health check endpoint\"\"\"\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"service\": \"Database Recommendation API\",\n",
        "        \"version\": \"1.0\",\n",
        "        \"supported_databases\": [db.value for db in DatabaseType],\n",
        "        \"model\": \"mistral:7b\"\n",
        "    }\n",
        "\n",
        "# =============================================================================\n",
        "# üöÄ SERVER STARTUP\n",
        "# =============================================================================\n",
        "\n",
        "def run_server():\n",
        "    \"\"\"Run FastAPI server\"\"\"\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=9008)\n",
        "\n",
        "# Start server in background thread\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "logger.info(\"‚è≥ Starting Database Recommendation server...\")\n",
        "time.sleep(5)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# üîó NGROK TUNNEL\n",
        "# =============================================================================\n",
        "\n",
        "NGROK_AUTH_TOKEN = \"33VYITl8jw9h78PdWIl1hgXJDk0_umeC43CgfdBrAnnEjBQu\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "try:\n",
        "    public_tunnel = ngrok.connect(9008, bind_tls=True)\n",
        "    public_url = public_tunnel.public_url\n",
        "except Exception as e:\n",
        "    logger.error(f\"‚ùå Ngrok error: {e}\")\n",
        "    print(f\"‚ùå Ngrok failed: {e}\")\n",
        "    print(\"üì° Server running locally on http://localhost:9008\")"
      ],
      "metadata": {
        "id": "MovpwFppi_6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîÑ KEEP-ALIVE LOOP FOR SERVER AND SESSION\n",
        "import time\n",
        "import threading\n",
        "\n",
        "def keep_alive():\n",
        "    \"\"\"–ü—Ä–æ—Å—Ç–æ–π —Ü–∏–∫–ª –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞ –∏ —Å–µ—Å—Å–∏–∏\"\"\"\n",
        "    while True:\n",
        "        print(f\"üïí Session alive at {time.strftime('%H:%M:%S')}\")\n",
        "        time.sleep(60)  # –°–æ–æ–±—â–µ–Ω–∏–µ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –≤ —Ñ–æ–Ω–æ–≤–æ–º –ø–æ—Ç–æ–∫–µ\n",
        "keep_alive_thread = threading.Thread(target=keep_alive, daemon=True)\n",
        "keep_alive_thread.start()\n",
        "\n",
        "print(\"‚úÖ Keep-alive loop started - server will stay active\")"
      ],
      "metadata": {
        "id": "FgForPt4oxpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}